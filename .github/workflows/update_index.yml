name: Update Library Index

on:
  push:
    # 移除路径限制，确保任何提交都能触发（调试用）
    # paths:
    #   - '**/info.json'

permissions:
  contents: write

jobs:
  update-index:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      
      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.10'
          
      - name: Generate Index
        run: |
          python3 <<EOF
          import os
          import json

          index = []
          # 使用代理 URL 以确保国内访问稳定性
          base_url = "https://mag.upxuu.com/library/file" 

          for item in os.listdir('.'):
              if os.path.isdir(item) and not item.startswith('.'):
                  info_path = os.path.join(item, 'info.json')
                  if os.path.exists(info_path):
                      try:
                          with open(info_path, 'r', encoding='utf-8') as f:
                              data = json.load(f)
                              # 添加通过代理的下载链接
                              data['downloadUrl'] = f"{base_url}/{item}/library.json"
                              index.append(data)
                      except Exception as e:
                          print(f"Error processing {info_path}: {e}")

          # 按时间戳倒序排列 (最新的在前)
          index.sort(key=lambda x: x.get('timestamp', 0), reverse=True)

          with open('index.json', 'w', encoding='utf-8') as f:
              json.dump(index, f, indent=2, ensure_ascii=False)
          
          print(f"Generated index with {len(index)} items.")
          EOF
          
      - name: Commit and Push
        run: |
          git config --global user.name "GitHub Action"
          git config --global user.email "action@github.com"
          
          # Clean workspace and Pull latest changes before committing
          git checkout .
          git pull --rebase origin main
          
          # Regenerate index after pull to include latest changes
          # (Actually we should generate after pull, but let's assume no conflict on index.json if we generate it fresh)
          # Re-run generation script here or move generation after pull?
          # Moving generation AFTER pull is safer to avoid conflicts if index.json existed.
          
          # Re-run generation logic (Inline for simplicity)
          python3 <<EOF
          import os
          import json
          import math
          import time

          index = []
          base_url = "https://mag.upxuu.com/library/file" 
          for item in os.listdir('.'):
              if os.path.isdir(item) and not item.startswith('.'):
                  info_path = os.path.join(item, 'info.json')
                  if os.path.exists(info_path):
                      try:
                          with open(info_path, 'r', encoding='utf-8') as f:
                              data = json.load(f)
                              data['downloadUrl'] = f"{base_url}/{item}/library.json"
                              index.append(data)
                      except Exception: pass
          
          # 按时间戳倒序排列 (最新的在前)
          index.sort(key=lambda x: x.get('timestamp', 0), reverse=True)
          
          # 分页逻辑：每页 10 个
          PAGE_SIZE = 10
          total_items = len(index)
          total_pages = math.ceil(total_items / PAGE_SIZE) if total_items > 0 else 0
          
          # 先清理旧的 index_*.json 和 index.json
          for f in os.listdir('.'):
              if f.startswith('index_') and f.endswith('.json'):
                  os.remove(f)
          if os.path.exists('index.json'):
              os.remove('index.json')
          
          # 生成 index_X.json
          for i in range(total_pages):
              start = i * PAGE_SIZE
              end = start + PAGE_SIZE
              page_data = index[start:end]
              filename = f"index_{i}.json"
              with open(filename, 'w', encoding='utf-8') as f:
                  json.dump(page_data, f, indent=2, ensure_ascii=False)
              print(f"Generated {filename} with {len(page_data)} items")
              
          # 生成 num.json
          meta_data = {
              "totalPages": total_pages,
              "totalItems": total_items,
              "pageSize": PAGE_SIZE,
              "lastUpdated": int(time.time() * 1000)
          }
          with open('num.json', 'w', encoding='utf-8') as f:
              json.dump(meta_data, f, indent=2, ensure_ascii=False)

          EOF
          
          # Add all index files and num.json
          # Use git add . to stage all changes including new files
          git add .
          # Ensure deletions are staged
          git add -u
          
          git commit -m "Update pagination indexes [skip ci]" || echo "No changes to commit"
          git push
